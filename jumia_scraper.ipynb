{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jumia Web Scraper using Requests, BeautifulSoup, and Pandas\n",
    "\n",
    "This notebook contains a complete Python script to scrape product data (name, price, old price, discount, and URL) from Jumia category pages and save the results into separate CSV files. The example uses the 'Smartphones' and 'Computing Devices' categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "%pip install pandas beautifulsoup4 requests --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Dict\n",
    "\n",
    "def extract_product_info(card) -> Dict[str, str]:\n",
    "    \"\"\"Extracts product details from a single BeautifulSoup product card element.\"\"\"\n",
    "    name_elem = card.select_one('h3.name')\n",
    "    price_elem = card.select_one('div.prc')\n",
    "    old_price_elem = card.select_one('div.old')\n",
    "    discount_elem = card.select_one('div.bdg._dsct')\n",
    "    link_elem = card.select_one('a.core')\n",
    "    \n",
    "    return {\n",
    "        'Product Name': name_elem.text.strip() if name_elem else 'N/A',\n",
    "        'Current Price': price_elem.text.strip() if price_elem else 'N/A',\n",
    "        'Old Price': old_price_elem.text.strip() if old_price_elem else 'N/A',\n",
    "        'Discount': discount_elem.text.strip() if discount_elem else 'N/A',\n",
    "        'Product URL': f\"https://www.jumia.co.ke{link_elem['href']}\" if link_elem and 'href' in link_elem.attrs else 'N/A'\n",
    "    }\n",
    "\n",
    "def scrape_jumia_category(url: str, category_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Scrapes a Jumia category page, processes product data, saves to CSV, and returns a DataFrame.\"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "                      \"(KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        # 1. Fetch the page content\n",
    "        print(f\"... Fetching data for {category_name} from: {url}\")\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "        \n",
    "        # 2. Parse the HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 3. Find all product cards (Jumia uses 'article.prd')\n",
    "        product_cards = soup.select('article.prd')\n",
    "        print(f\"âœ“ Found {len(product_cards)} {category_name} on the page\")\n",
    "        \n",
    "        # 4. Extract info from each card\n",
    "        products = [\n",
    "            extract_product_info(card) \n",
    "            for card in product_cards\n",
    "        ]\n",
    "        \n",
    "        # 5. Create DataFrame and save to CSV\n",
    "        df = pd.DataFrame(products)\n",
    "        filename = f\"jumia_{category_name.lower().replace(' ', '_')}.csv\"\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"âœ“ Data saved to {filename}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"âœ— Error fetching data for {category_name}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "\n",
    "# Scrape Smartphones\n",
    "smartphones_df = scrape_jumia_category(\n",
    "    url=\"https://www.jumia.co.ke/smartphones/\",\n",
    "    category_name=\"Smartphones\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“± Smartphone Sample Data:\")\n",
    "if not smartphones_df.empty:\n",
    "    display(smartphones_df.head(5))\n",
    "\n",
    "# Scrape Computing Devices\n",
    "computing_df = scrape_jumia_category(\n",
    "    url=\"https://www.jumia.co.ke/computing/\",\n",
    "    category_name=\"Computing Devices\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’» Computing Devices Sample Data:\")\n",
    "if not computing_df.empty:\n",
    "    display(computing_df.head(5))\n",
    "\n",
    "# Summary\n",
    "print(\"\\nðŸ“Š Scraping Summary:\")\n",
    "print(f\"Total Smartphones: {len(smartphones_df)}\")\n",
    "print(f\"Total Computing Devices: {len(computing_df)}\")\n",
    "print(f\"\\nTotal Products Scraped: {len(smartphones_df) + len(computing_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}